{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Machine Learning With TensorFlow: What Does Your Doodle Look Like? Image Classification With TensorFlow\n",
    "\n",
    "Note: you can install the requirements file for this notebook if you want to install all the libraries at once. Open a new terminal window, navigate to the folder with the \"requirements_jupyter.txt\" and run the following command:\n",
    "\n",
    "pip3 install -r requirements_jupyter.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements_jupyter.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST data from Tensorflow's tutorials library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-22f22f56a5a0>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/manuelamunategui/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/manuelamunategui/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/manuelamunategui/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/manuelamunategui/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/manuelamunategui/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/manuelamunategui/Library/Python/3.6/lib/python/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# this will take a while the first time you call it as it will download the \n",
    "# data from the internet - subsequent runs will use the data stored locally\n",
    "# if you get an SSL error, try fix: \"/Applications/Python\\ 3.6/Install\\ Certificates.command\"\n",
    "# https://github.com/tensorflow/tensorflow/issues/10779\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "batch = mnist.train.next_batch(1)\n",
    "sample_digit = batch[0]\n",
    "sample_digit = sample_digit.reshape(28, 28)\n",
    "plt.imshow(sample_digit, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_digit = mnist.train.images[0]\n",
    "first_digit = np.array(first_digit, dtype='float')\n",
    "first_digit = first_digit.reshape((28, 28))\n",
    "plt.imshow(first_digit, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the label in legible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Modeling\n",
    "Based the following this tutorial (but with some modefications to handle saving of model for later re-use):\n",
    "https://www.tensorflow.org/versions/r1.1/get_started/mnist/pros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 0.1022\n",
      "100 0.8494\n",
      "200 0.9164\n",
      "300 0.9269\n",
      "400 0.9419\n",
      "500 0.9483\n",
      "600 0.9537\n",
      "700 0.9587\n",
      "800 0.9603\n",
      "900 0.9652\n",
      "1000 0.9674\n",
      "1100 0.9649\n",
      "1200 0.9691\n",
      "1300 0.9696\n",
      "1400 0.9734\n",
      "1500 0.9731\n",
      "1600 0.9737\n",
      "1700 0.9742\n",
      "1800 0.9757\n",
      "1900 0.9776\n",
      "2000 0.9764\n",
      "Model saved in file:  /Users/manuelamunategui/Desktop/ml-web-downloads/chapter8/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = os.path.join(os.getcwd(), 'model.ckpt')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# First convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Densely Connected Layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout Layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Training steps\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    max_steps = 2000\n",
    "    for step in range(max_steps):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(50)\n",
    "        if (step % 100) == 0:\n",
    "            print(step, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "    print(max_steps, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_file)\n",
    "    print (\"Model saved in file: \", save_path)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading up a saved and trained model to run our predictions\n",
    "We need to rebuild the plumbing but don't need to load the data or run the model, simply feed the checkpoints to the saver function. To test the model we will add a PNG image: 'mnist_5.png', so we're looking for the model to predict \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/manuelamunategui/Desktop/ml-web-downloads/chapter8/model.ckpt\n",
      "Model restored.\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_file = os.path.join(os.getcwd(), 'model.ckpt')\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# restore the saved session\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# set all variables needed like in orginal model \n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# First convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Densely Connected Layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout Layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    " \n",
    "# fix image to be in abide by our model's format requirements\n",
    "img = Image.open('mnist_5.png')\n",
    "img = img.resize([28,28])\n",
    "corrected_img = Image.new(\"RGBA\", (28, 28), \"white\")\n",
    "corrected_img.paste(img, (0,0), img)\n",
    "corrected_img = np.asarray(corrected_img)\n",
    "# remove color dimensions\n",
    "corrected_img = corrected_img[:, :, 0]\n",
    "corrected_img = np.invert(corrected_img)\n",
    "# flatten\n",
    "corrected_img = corrected_img.reshape([784])\n",
    "# center around 0-1\n",
    "img = np.asarray(corrected_img, dtype=np.float32) / 255.\n",
    " \n",
    "# Training steps\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver.restore(sess, save_file)\n",
    "    print(\"Model restored.\")\n",
    "    print(sess.run(tf.argmax(y_conv,1), feed_dict={x: [img], keep_prob: 1.0}))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
